{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "train - yes done\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "101000\n",
      "102000\n",
      "103000\n",
      "104000\n",
      "105000\n",
      "106000\n",
      "107000\n",
      "108000\n",
      "109000\n",
      "110000\n",
      "111000\n",
      "112000\n",
      "113000\n",
      "114000\n",
      "115000\n",
      "116000\n",
      "117000\n",
      "118000\n",
      "119000\n",
      "120000\n",
      "121000\n",
      "122000\n",
      "123000\n",
      "124000\n",
      "125000\n",
      "126000\n",
      "127000\n",
      "128000\n",
      "129000\n",
      "130000\n",
      "131000\n",
      "132000\n",
      "133000\n",
      "134000\n",
      "135000\n",
      "136000\n",
      "137000\n",
      "138000\n",
      "139000\n",
      "140000\n",
      "141000\n",
      "142000\n",
      "143000\n",
      "144000\n",
      "145000\n",
      "146000\n",
      "147000\n",
      "148000\n",
      "149000\n",
      "150000\n",
      "151000\n",
      "152000\n",
      "153000\n",
      "154000\n",
      "155000\n",
      "156000\n",
      "157000\n",
      "158000\n",
      "159000\n",
      "160000\n",
      "train - no done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "def bgr2rgb(img):\n",
    "    return img[...,::-1]\n",
    "\n",
    "def load_color_img(path):\n",
    "    return np.array( bgr2rgb(cv.imread(path)) )\n",
    "\n",
    "random.seed(3)\n",
    "\n",
    "data_path = os.getcwd() + \"/eye_data\" + \"/set1\"\n",
    "eyes_path = data_path + \"/images\" + \"/\"\n",
    "vessels_path = data_path + \"/vessels\" + \"/\"\n",
    "\n",
    "yes_path = data_path + \"/classes/yes_original\" + \"/\"\n",
    "no_path = data_path + \"/classes/no_original\" + \"/\"\n",
    "\n",
    "yeses = os.listdir(yes_path)\n",
    "noes = os.listdir(no_path)\n",
    "\n",
    "random.shuffle(yeses)\n",
    "random.shuffle(noes)\n",
    "\n",
    "yeses = yeses[:80000]\n",
    "noes = noes[:80000]\n",
    "\n",
    "labels = {\n",
    "    'yes' : 1,\n",
    "    'no' : 0\n",
    "}\n",
    "\n",
    "train_x = []\n",
    "train_y = []\n",
    "train_test_div = int(1.0*len(yeses))\n",
    "\n",
    "for file in yeses[:train_test_div]:\n",
    "    train_x.append(load_color_img(yes_path+file))\n",
    "    train_y.append(1)\n",
    "    if len(train_x) % 1000 == 0:\n",
    "        print(len(train_x))\n",
    "print('train - yes done')\n",
    "for file in noes[:train_test_div]:\n",
    "    train_x.append(load_color_img(no_path+file))\n",
    "    train_y.append(0)\n",
    "    if len(train_x) % 1000 == 0:\n",
    "        print(len(train_x))\n",
    "print('train - no done')\n",
    "    \n",
    "train_x = np.array(train_x, dtype=np.float32)\n",
    "#test_x = np.array(test_x, dtype=np.float32)\n",
    "\n",
    "train_x /= 255.0\n",
    "#test_x /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariu\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(160000, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_y_cat = to_categorical(train_y)\n",
    "train_y_cat.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((128000, 33, 33, 3), (32000, 33, 33, 3))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x, valid_x, train_label, valid_label = train_test_split(train_x, train_y_cat, test_size=0.2, random_state=13)\n",
    "train_x.shape, valid_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 33, 33, 32)        896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 33, 33, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 17, 17, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 17, 17, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 17, 17, 64)        18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               409728    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 503,234\n",
      "Trainable params: 503,234\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 128000 samples, validate on 32000 samples\n",
      "Epoch 1/20\n",
      "128000/128000 [==============================] - 886s 7ms/step - loss: 0.3468 - acc: 0.8429 - val_loss: 0.2655 - val_acc: 0.8894\n",
      "Epoch 2/20\n",
      "128000/128000 [==============================] - 775s 6ms/step - loss: 0.2646 - acc: 0.8947 - val_loss: 0.2615 - val_acc: 0.8935\n",
      "Epoch 3/20\n",
      "128000/128000 [==============================] - 716s 6ms/step - loss: 0.2547 - acc: 0.8994 - val_loss: 0.2422 - val_acc: 0.9042\n",
      "Epoch 4/20\n",
      "128000/128000 [==============================] - 639s 5ms/step - loss: 0.2485 - acc: 0.9021 - val_loss: 0.2487 - val_acc: 0.9001\n",
      "Epoch 5/20\n",
      "128000/128000 [==============================] - 619s 5ms/step - loss: 0.2427 - acc: 0.9041 - val_loss: 0.2388 - val_acc: 0.9065\n",
      "Epoch 6/20\n",
      "128000/128000 [==============================] - 617s 5ms/step - loss: 0.2387 - acc: 0.9068 - val_loss: 0.2256 - val_acc: 0.9118\n",
      "Epoch 7/20\n",
      "128000/128000 [==============================] - 613s 5ms/step - loss: 0.2375 - acc: 0.9069 - val_loss: 0.2418 - val_acc: 0.9044\n",
      "Epoch 8/20\n",
      "128000/128000 [==============================] - 620s 5ms/step - loss: 0.2329 - acc: 0.9092 - val_loss: 0.2257 - val_acc: 0.9120\n",
      "Epoch 9/20\n",
      "128000/128000 [==============================] - 614s 5ms/step - loss: 0.2306 - acc: 0.9099 - val_loss: 0.2296 - val_acc: 0.9097\n",
      "Epoch 10/20\n",
      "128000/128000 [==============================] - 611s 5ms/step - loss: 0.2279 - acc: 0.9115 - val_loss: 0.2101 - val_acc: 0.9171\n",
      "Epoch 11/20\n",
      "128000/128000 [==============================] - 617s 5ms/step - loss: 0.2244 - acc: 0.9121 - val_loss: 0.2167 - val_acc: 0.9145\n",
      "Epoch 12/20\n",
      "128000/128000 [==============================] - 617s 5ms/step - loss: 0.2223 - acc: 0.9141 - val_loss: 0.2119 - val_acc: 0.9176\n",
      "Epoch 13/20\n",
      "128000/128000 [==============================] - 632s 5ms/step - loss: 0.2215 - acc: 0.9150 - val_loss: 0.1996 - val_acc: 0.9228\n",
      "Epoch 14/20\n",
      "128000/128000 [==============================] - 817s 6ms/step - loss: 0.2186 - acc: 0.9155 - val_loss: 0.2147 - val_acc: 0.9163\n",
      "Epoch 15/20\n",
      "128000/128000 [==============================] - 745s 6ms/step - loss: 0.2156 - acc: 0.9165 - val_loss: 0.2174 - val_acc: 0.9168\n",
      "Epoch 16/20\n",
      "128000/128000 [==============================] - 771s 6ms/step - loss: 0.2141 - acc: 0.9174 - val_loss: 0.2108 - val_acc: 0.9193\n",
      "Epoch 17/20\n",
      "128000/128000 [==============================] - 697s 5ms/step - loss: 0.2139 - acc: 0.9180 - val_loss: 0.2121 - val_acc: 0.9187\n",
      "Epoch 18/20\n",
      "128000/128000 [==============================] - 687s 5ms/step - loss: 0.2129 - acc: 0.9181 - val_loss: 0.2247 - val_acc: 0.9133\n",
      "Epoch 19/20\n",
      "128000/128000 [==============================] - 683s 5ms/step - loss: 0.2121 - acc: 0.9184 - val_loss: 0.2182 - val_acc: 0.9149\n",
      "Epoch 20/20\n",
      "128000/128000 [==============================] - 687s 5ms/step - loss: 0.2103 - acc: 0.9191 - val_loss: 0.1990 - val_acc: 0.9227\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 20\n",
    "num_classes = len(labels)\n",
    "input_shape = train_x[0].shape\n",
    "\n",
    "fashion_model = Sequential()\n",
    "fashion_model.add(Conv2D(32, kernel_size=(3, 3),activation='linear',padding='same',input_shape=input_shape))\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))\n",
    "fashion_model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "fashion_model.add(Dropout(0.25))\n",
    "fashion_model.add(Conv2D(64, (3, 3), activation='linear',padding='same'))\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))\n",
    "fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "fashion_model.add(Dropout(0.25))\n",
    "fashion_model.add(Conv2D(128, (3, 3), activation='linear',padding='same'))\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))                  \n",
    "fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "fashion_model.add(Dropout(0.3))\n",
    "fashion_model.add(Flatten())\n",
    "fashion_model.add(Dense(128, activation='linear'))\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))           \n",
    "fashion_model.add(Dropout(0.3))\n",
    "fashion_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "fashion_model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "                      optimizer=keras.optimizers.Adam(),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "\n",
    "fashion_model.summary()\n",
    "\n",
    "fashion_train = fashion_model.fit(train_x, train_label, \n",
    "                                  batch_size=batch_size,\n",
    "                                  epochs=epochs,\n",
    "                                  verbose=1,\n",
    "                                  validation_data=(valid_x, valid_label))\n",
    "fashion_model.save(\"std_model_original_size.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
