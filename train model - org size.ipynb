{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n",
      "5000\n",
      "7500\n",
      "10000\n",
      "12500\n",
      "15000\n",
      "17500\n",
      "20000\n",
      "22500\n",
      "25000\n",
      "27500\n",
      "30000\n",
      "32500\n",
      "35000\n",
      "37500\n",
      "40000\n",
      "42500\n",
      "45000\n",
      "47500\n",
      "50000\n",
      "52500\n",
      "55000\n",
      "57500\n",
      "60000\n",
      "62500\n",
      "65000\n",
      "67500\n",
      "70000\n",
      "72500\n",
      "75000\n",
      "77500\n",
      "80000\n",
      "82500\n",
      "85000\n",
      "87500\n",
      "90000\n",
      "92500\n",
      "95000\n",
      "97500\n",
      "100000\n",
      "train - yes done\n",
      "102500\n",
      "105000\n",
      "107500\n",
      "110000\n",
      "112500\n",
      "115000\n",
      "117500\n",
      "120000\n",
      "122500\n",
      "125000\n",
      "127500\n",
      "130000\n",
      "132500\n",
      "135000\n",
      "137500\n",
      "140000\n",
      "142500\n",
      "145000\n",
      "147500\n",
      "150000\n",
      "152500\n",
      "155000\n",
      "157500\n",
      "160000\n",
      "162500\n",
      "165000\n",
      "167500\n",
      "170000\n",
      "172500\n",
      "175000\n",
      "177500\n",
      "180000\n",
      "182500\n",
      "185000\n",
      "187500\n",
      "190000\n",
      "192500\n",
      "195000\n",
      "197500\n",
      "200000\n",
      "train - no done\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1614da6aba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def bgr2rgb(img):\n",
    "    return img[...,::-1]\n",
    "\n",
    "def load_color_img(path):\n",
    "    return np.array( bgr2rgb(cv.imread(path)), dtype=np.float32 )\n",
    "\n",
    "def load_color_img2(path):\n",
    "    img = cv.imread(path)\n",
    "    return img.transpose(2, 1, 0)\n",
    "\n",
    "random.seed(3)\n",
    "\n",
    "data_path = os.getcwd() + \"/eye_data\" + \"/set1\"\n",
    "eyes_path = data_path + \"/images\" + \"/\"\n",
    "vessels_path = data_path + \"/vessels\" + \"/\"\n",
    "\n",
    "yes_path = data_path + \"/classes/yes_original\" + \"/\"\n",
    "no_path = data_path + \"/classes/no_original\" + \"/\"\n",
    "\n",
    "yeses = os.listdir(yes_path)\n",
    "noes = os.listdir(no_path)\n",
    "\n",
    "random.shuffle(yeses)\n",
    "random.shuffle(noes)\n",
    "\n",
    "yeses = yeses[:100000]\n",
    "noes = noes[:100000]\n",
    "\n",
    "test = load_color_img(yes_path + yeses[0])\n",
    "height = test.shape[0]\n",
    "width = test.shape[1]\n",
    "channels = test.shape[2]\n",
    "\n",
    "labels = {\n",
    "    'yes' : 1,\n",
    "    'no' : 0\n",
    "}\n",
    "\n",
    "train_x = []\n",
    "train_y = []\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "N = len(yeses) + len(noes)\n",
    "train_x = np.empty((N, height, width, channels), dtype=np.float32)\n",
    "train_y = np.empty(N, dtype=np.uint8)\n",
    "\n",
    "idx = 0\n",
    "for file in yeses:\n",
    "    \n",
    "    im = load_color_img(yes_path+file)\n",
    "    #im_s = sess.run(tf.image.per_image_standardization(im))\n",
    "    \n",
    "    train_x[idx] = im\n",
    "    train_y[idx] = 1\n",
    "    idx+=1\n",
    "\n",
    "    if idx % 2500 == 0:\n",
    "        print(idx)\n",
    "print('train - yes done')\n",
    "\n",
    "for file in noes:\n",
    "    \n",
    "    im = load_color_img(no_path+file)\n",
    "    #im_s = sess.run(tf.image.per_image_standardization(im))\n",
    "    \n",
    "    train_x[idx] = im\n",
    "    train_y[idx] = 0\n",
    "    idx += 1\n",
    "\n",
    "    if idx % 2500 == 0:\n",
    "        print(idx)\n",
    "print('train - no done')\n",
    "\n",
    "mean_img = np.average(train_x, axis=(1, 2))\n",
    "std_dev_img = np.std(train_x, axis=(1, 2))\n",
    "std_dev_img[std_dev_img == 0.0] = 0.00000001\n",
    "\n",
    "plt.imshow(train_x[10])\n",
    "plt.show()\n",
    "for i in range(N):\n",
    "    for ch in range(3):\n",
    "        train_x[i, :, :, ch] -= mean_img[i, ch]\n",
    "        train_x[i, :, :, ch] /= std_dev_img[i, ch]\n",
    "\n",
    "#for i in range(N):\n",
    "#    print(train_x[i].shape, mean_img.shape)\n",
    "#    train_x[i] -= mean_img\n",
    "#    train_x[i] /= std_dev_im\n",
    "\n",
    "#train_x /= 255.0\n",
    "#test_x /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 2)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_y_cat = to_categorical(train_y)\n",
    "train_y_cat.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((160000, 33, 33, 3), (40000, 33, 33, 3))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x, valid_x, train_label, valid_label = train_test_split(train_x, train_y_cat, test_size=0.2, random_state=13)\n",
    "train_x.shape, valid_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_17 (Conv2D)           (None, 33, 33, 48)        1344      \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 33, 33, 48)        192       \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 33, 33, 48)        20784     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 33, 33, 48)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 33, 33, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 17, 17, 48)        0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 17, 17, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 17, 17, 64)        27712     \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 17, 17, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 9, 9, 64)          36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 9, 9, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 428)               685228    \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 428)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2)                 858       \n",
      "=================================================================\n",
      "Total params: 773,750\n",
      "Trainable params: 773,302\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "Train on 160000 samples, validate on 40000 samples\n",
      "Epoch 1/150\n",
      "160000/160000 [==============================] - 6016s 38ms/step - loss: 0.2491 - acc: 0.9029 - val_loss: 0.2457 - val_acc: 0.9064\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.90643, saving model to C:\\Users\\mariu\\Documents\\Eye Blood Vessels/eye_data/set1/models/weights.01-0.25.hdf5\n",
      "Epoch 2/150\n",
      "160000/160000 [==============================] - 5952s 37ms/step - loss: 0.2102 - acc: 0.9209 - val_loss: 0.2080 - val_acc: 0.9215\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.90643 to 0.92148, saving model to C:\\Users\\mariu\\Documents\\Eye Blood Vessels/eye_data/set1/models/weights.02-0.21.hdf5\n",
      "Epoch 3/150\n",
      "160000/160000 [==============================] - 5742s 36ms/step - loss: 0.2002 - acc: 0.9248 - val_loss: 0.2017 - val_acc: 0.9237\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.92148 to 0.92375, saving model to C:\\Users\\mariu\\Documents\\Eye Blood Vessels/eye_data/set1/models/weights.03-0.20.hdf5\n",
      "Epoch 4/150\n",
      "160000/160000 [==============================] - 5629s 35ms/step - loss: 0.1943 - acc: 0.9275 - val_loss: 0.1846 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.92375 to 0.92997, saving model to C:\\Users\\mariu\\Documents\\Eye Blood Vessels/eye_data/set1/models/weights.04-0.18.hdf5\n",
      "Epoch 5/150\n",
      "160000/160000 [==============================] - 5596s 35ms/step - loss: 0.1881 - acc: 0.9299 - val_loss: 0.1829 - val_acc: 0.9332\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.92997 to 0.93320, saving model to C:\\Users\\mariu\\Documents\\Eye Blood Vessels/eye_data/set1/models/weights.05-0.18.hdf5\n",
      "Epoch 6/150\n",
      "160000/160000 [==============================] - 5679s 35ms/step - loss: 0.1830 - acc: 0.9318 - val_loss: 0.1825 - val_acc: 0.9331\n",
      "\n",
      "Epoch 00006: val_acc did not improve\n",
      "Epoch 7/150\n",
      "160000/160000 [==============================] - 5946s 37ms/step - loss: 0.1797 - acc: 0.9329 - val_loss: 0.1844 - val_acc: 0.9325\n",
      "\n",
      "Epoch 00007: val_acc did not improve\n",
      "Epoch 8/150\n",
      "160000/160000 [==============================] - 5917s 37ms/step - loss: 0.1753 - acc: 0.9347 - val_loss: 0.1798 - val_acc: 0.9330\n",
      "\n",
      "Epoch 00008: val_acc did not improve\n",
      "Epoch 9/150\n",
      "160000/160000 [==============================] - 5606s 35ms/step - loss: 0.1708 - acc: 0.9353 - val_loss: 0.1783 - val_acc: 0.9343\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.93320 to 0.93425, saving model to C:\\Users\\mariu\\Documents\\Eye Blood Vessels/eye_data/set1/models/weights.09-0.18.hdf5\n",
      "Epoch 10/150\n",
      "160000/160000 [==============================] - 5594s 35ms/step - loss: 0.1672 - acc: 0.9378 - val_loss: 0.1805 - val_acc: 0.9343\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.93425 to 0.93432, saving model to C:\\Users\\mariu\\Documents\\Eye Blood Vessels/eye_data/set1/models/weights.10-0.18.hdf5\n",
      "Epoch 11/150\n",
      "160000/160000 [==============================] - 5587s 35ms/step - loss: 0.1628 - acc: 0.9388 - val_loss: 0.1856 - val_acc: 0.9341\n",
      "\n",
      "Epoch 00011: val_acc did not improve\n",
      "Epoch 12/150\n",
      " 85248/160000 [==============>...............] - ETA: 40:26 - loss: 0.1601 - acc: 0.9399"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 150\n",
    "num_classes = len(labels)\n",
    "input_shape = train_x[0].shape\n",
    "\n",
    "fashion_model = Sequential()\n",
    "\n",
    "fashion_model.add(Conv2D(48, kernel_size=(3, 3),activation='relu',padding='same',input_shape=input_shape))\n",
    "#fashion_model.add(LeakyReLU(alpha=0.1))\n",
    "fashion_model.add(BatchNormalization())\n",
    "#fashion_model.add(Dropout(0.25))\n",
    "#fashion_model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "\n",
    "fashion_model.add(Conv2D(48, (3, 3), activation='linear',padding='same'))\n",
    "fashion_model.add(LeakyReLU())\n",
    "fashion_model.add(BatchNormalization())\n",
    "fashion_model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "fashion_model.add(Dropout(0.25))\n",
    "\n",
    "fashion_model.add(Conv2D(64, (3, 3), activation='relu',padding='same'))\n",
    "#fashion_model.add(LeakyReLU())\n",
    "fashion_model.add(BatchNormalization())\n",
    "fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "fashion_model.add(Dropout(0.25))\n",
    "\n",
    "fashion_model.add(Conv2D(64, (3, 3), activation='linear',padding='same'))\n",
    "fashion_model.add(LeakyReLU())     \n",
    "fashion_model.add(BatchNormalization())\n",
    "fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "fashion_model.add(Dropout(0.25))\n",
    "\n",
    "fashion_model.add(Flatten())\n",
    "fashion_model.add(Dense(428, activation='relu'))\n",
    "#fashion_model.add(BatchNormalization())\n",
    "fashion_model.add(Dropout(0.25))\n",
    "fashion_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "fashion_model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "                      optimizer=keras.optimizers.Adam(),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "filepath = data_path + \"/models/\" + \"weights.{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', \n",
    "                             verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "fashion_model.summary()\n",
    "fashion_train = fashion_model.fit(train_x, train_label, \n",
    "                                  batch_size=batch_size,\n",
    "                                  epochs=epochs,\n",
    "                                  verbose=1,\n",
    "                                  callbacks=callbacks_list,\n",
    "                                  validation_data=(valid_x, valid_label))\n",
    "fashion_model.save(\"originalSizeModel - new.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
